{
 "metadata": {
  "name": "",
  "signature": "sha256:06fec5649172fd13237001091a23283df21d14da819b5ee54983122d4a196ed6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook to get data from efetch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'quek'\n",
      "import requests\n",
      "import json\n",
      "\n",
      "\n",
      "def chunks(l, n):\n",
      "    \"\"\" Yield successive n-sized chunks from l.\n",
      "    \"\"\"\n",
      "    for i in xrange(0, len(l), n):\n",
      "        yield l[i:i+n]\n",
      "\n",
      "efetch_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=Pubmed&id=' #1447221,1231231&retmode=xml\n",
      "upjson = 'sample_data/up.json'\n",
      "downjson = 'sample_data/down.json'\n",
      "\n",
      "\n",
      "\n",
      "def conductEfetch(filename):\n",
      "    with open(filename) as f:\n",
      "        efetchJson = json.load(f)\n",
      "        pmids = efetchJson['ids']\n",
      "        \n",
      "    chunky_pmid = chunks(pmids, 500)\n",
      "    results = []\n",
      "\n",
      "    for ids in chunky_pmid:\n",
      "        ids = [str(x) for x in ids]\n",
      "        ids = \",\".join(ids)\n",
      "        url = \"%s%s&retmode=xml\" % (efetch_url, ids)\n",
      "        response = requests.get(url)\n",
      "        results.append(response.text)\n",
      "    return results\n",
      "\n",
      "upResults = conductEfetch(upjson)\n",
      "downResults = conductEfetch(downjson)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parsing XML Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup as Bs4\n",
      "\n",
      "\n",
      "def findInterest(entries, fields):\n",
      "    \"\"\"\n",
      "    entries is a soup object\n",
      "    fields is a list of nodes that we are interested in\n",
      "    \"\"\"\n",
      "    \n",
      "    return_dict = {}\n",
      "    for interest in fields:\n",
      "        try:\n",
      "            result = entries.find(interest)\n",
      "            result = result.text\n",
      "            \n",
      "        except AttributeError: \n",
      "            result = 'None'\n",
      "        return_dict[interest] = result     \n",
      "        \n",
      "    return return_dict\n",
      "\n",
      "            \n",
      "    \n",
      "        \n",
      "\n",
      "fields = ['articletitle','abstracttext','title']\n",
      "\n",
      "\n",
      "BigDict = {}\n",
      "\n",
      "\n",
      "for x in upResults:\n",
      "    soup =Bs4(x)\n",
      "    results = soup.find_all('pubmedarticle')\n",
      "    for entries in results:\n",
      "        entries_dict = findInterest(entries, fields)\n",
      "        pmid = entries.find('pmid').text\n",
      "        url = \"http://www.ncbi.nlm.nih.gov/pubmed%s\" % pmid\n",
      "        entries_dict['url'] = url\n",
      "        BigDict[pmid] = entries_dict\n",
      "        \n",
      "            \n",
      "        \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Convert Dictionary to json"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json \n",
      "with open('sample_data/pubmed_detail.json', 'w') as f:\n",
      "    json.dump(BigDict,f, indent=4, separators=(',', ': '))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "sample_data/pubmed_detail.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "bash: line 1: sample_data/pubmed_detail.json: Permission denied\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}